models:
  llama:
    model_name: "llama-2-70b-chat"
    temperature: 0.7
    max_tokens: 2000
    top_p: 0.95
    frequency_penalty: 0
    presence_penalty: 0
    
  gpt4:
    model_name: "gpt-4"
    temperature: 0.7
    max_tokens: 2000
    top_p: 0.95
    frequency_penalty: 0
    presence_penalty: 0 